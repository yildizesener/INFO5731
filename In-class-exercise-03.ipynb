{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The third In-class-exercise (9/16/2020, 20 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to under users' information needs, then collect the data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (8 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPlease write you answer here:\\nLonelines is common emaotioanl problem among people. Espeacillay during the pandemic, this situation may cause some \\nmental health problems. Thereby, the words that are highly associated with 'lonely' and 'alone' will be indetified\\nin order to find people who strugle with expressing their loneliness so that the proper solutions can be find for \\nthose who are struggling with loneliness. \\n\\nFor the reseach project, the tweets will be collceted which has the hastags '#alone' and\\n'#lonely'. After the data collection process, I will convert the data into structured form and apply a simple bag-of-\\nwords model to select the words that are most appeared in the tweets.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
    "\n",
    "'''\n",
    "Please write you answer here:\n",
    "Lonelines is common emaotioanl problem among people. Espeacillay during the pandemic, this situation may cause some \n",
    "mental health problems. Thereby, the words that are highly associated with 'lonely' and 'alone' will be indetified\n",
    "in order to find people who strugle with expressing their loneliness so that the proper solutions can be find for \n",
    "those who are struggling with loneliness. \n",
    "\n",
    "For the reseach project, the tweets will be collceted which has the hastags '#alone' and\n",
    "'#lonely'. After the data collection process, I will convert the data into structured form and apply a simple bag-of-\n",
    "words model to select the words that are most appeared in the tweets.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 (12 points): Write python code to collect 500 items of the data you plan to collect above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occured during an HTTP request: HTTP Error 404: Not Found\n",
      "Try to open in browser: https://twitter.com/search?q=%23alone%20near%3A%22Dallas%2C%20Texas%22%20within%3A15mi%20since%3A2016-09-14%20until%3A2020-09-16&src=typd\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yildizesener/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "\n",
    "#Function defining all the required fields\n",
    "def get_twitter_info():\n",
    "    tweet_df[\"tweet_text\"] = tweet_df[\"got_criteria\"].apply(lambda x: x.text)\n",
    "    tweet_df[\"date\"] = tweet_df[\"got_criteria\"].apply(lambda x: x.date)\n",
    "    tweet_df[\"hashtags\"] = tweet_df[\"got_criteria\"].apply(lambda x: x.hashtags)\n",
    "    tweet_df[\"link\"] = tweet_df[\"got_criteria\"].apply(lambda x: x.permalink)\n",
    "\n",
    "\n",
    "keyword = \"#alone\"           #Keyword required for search criteria\n",
    "oldest_date = \"2016-09-14\"      #oldest date for extraction\n",
    "newest_date = \"2020-09-16\"      #Newest date for extraction\n",
    "locations =[\"Dallas, Texas\"]         #Location of the tweet to be extracted\n",
    "\n",
    "number_tweets =10000            #Number of tweets to be extracted\n",
    "\n",
    "#get old tweets\n",
    "tweetCriteria_list = []\n",
    "for location in locations:    \n",
    "    try:\n",
    "        tweetCriteria = got.manager.TweetCriteria().setQuerySearch(keyword).setSince(oldest_date).setUntil(newest_date).setNear(location).setMaxTweets(number_tweets)\n",
    "        tweetCriteria_list.append(tweetCriteria)\n",
    "    except:\n",
    "        continue   \n",
    "#create twitter info for each city\n",
    "tweet_dict = {}                   \n",
    "for criteria, location in zip(tweetCriteria_list, locations):\n",
    "    tweets = got.manager.TweetManager.getTweets(criteria)\n",
    "    tweet_dict[location] = tweets\n",
    "    \n",
    "#create df\n",
    "tweet_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in tweet_dict.items() ]))\n",
    "tweet_df['tweet_count'] = tweet_df.index\n",
    "tweet_df = pd.melt(tweet_df, id_vars=[\"tweet_count\"], var_name='City', value_name='got_criteria')\n",
    "tweet_df = tweet_df.dropna()\n",
    "\n",
    "#extract twitter information\n",
    "get_twitter_info()\n",
    "tweet_df = tweet_df.drop(\"got_criteria\", 1)\n",
    "tweet_df.head()\n",
    "\n",
    "# #export the frame to a csv file\n",
    "# tweet_df.to_csv(\"UK_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fb77272a5912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tweet_df' is not defined"
     ]
    }
   ],
   "source": [
    "tweet_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
